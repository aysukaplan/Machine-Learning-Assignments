{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a7c4859",
   "metadata": {},
   "source": [
    "# BBM409 Assignment_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e06ed",
   "metadata": {},
   "source": [
    "\n",
    "## PART 1: Classification of News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d7f2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d5ed7",
   "metadata": {},
   "source": [
    "### Implementing k Nearest Neighbor Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7b3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclid distance function for calculating distance between two points to be used for KNN algorithms\n",
    "def euclid_distance(x1, x2):\n",
    "    distance = np.sqrt(np.sum((x1-x2)**2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7080d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own KNN algorithm class which implemented from scratch\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([])\n",
    "        for x in X:\n",
    "            predictions = np.append(predictions, self._predict(x))\n",
    "        return predictions\n",
    "\n",
    "    def _predict(self, x):\n",
    "\n",
    "        distances = np.array([])\n",
    "\n",
    "        for x_train in self.X_train :\n",
    "            distance = euclid_distance(x, x_train)\n",
    "            distances = np.append(distances, distance)\n",
    "\n",
    "        k_indices = np.array([])\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        k_nearest_labels = np.array([])\n",
    "\n",
    "        for i in k_indices:\n",
    "            k_nearest_labels = np.append(k_nearest_labels, self.y_train.iloc[i])\n",
    "\n",
    "        most_common = Counter(k_nearest_labels).most_common()\n",
    "\n",
    "        return most_common[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171a6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own weighted KNN algorithm class which implemented from scratch\n",
    "class WeightedKNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([])\n",
    "        for x in X:\n",
    "            predictions = np.append(predictions, self._predict(x))\n",
    "        return predictions\n",
    "\n",
    "    def _predict(self, x):\n",
    "\n",
    "        distances = np.array([])\n",
    "\n",
    "        for x_train in self.X_train:\n",
    "            distance = euclid_distance(x, x_train)\n",
    "            distances = np.append(distances, distance)\n",
    "\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        weighted_labels = {}\n",
    "\n",
    "        for i in k_indices:\n",
    "            label = self.y_train.iloc[i]\n",
    "            distance = distances[i]\n",
    "\n",
    "            # Using inverse distance as weight\n",
    "            weight = 1 / (distance + 1e-5)  # Adding a small value to avoid division by zero\n",
    "\n",
    "            if label not in weighted_labels:\n",
    "                weighted_labels[label] = 0\n",
    "            weighted_labels[label] += weight\n",
    "\n",
    "        # Find the label with the highest weighted sum\n",
    "        most_weighted_label = max(weighted_labels, key=weighted_labels.get)\n",
    "\n",
    "        return most_weighted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fcae8",
   "metadata": {},
   "source": [
    "### Functions to be used later on this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac87e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate confusion matrix parameters True Positive, True Negative, False Positive, False Negative\n",
    "def calculate_confusion_matrix(y_true, y_pred, num_classes):\n",
    "    # Initialize counts for TP, TN, FP, FN for each class\n",
    "    tp = [0] * num_classes\n",
    "    tn = [0] * num_classes\n",
    "    fp = [0] * num_classes\n",
    "    fn = [0] * num_classes\n",
    "\n",
    "    # Iterate over each instance\n",
    "    for i in range(len(y_true)):\n",
    "        true_label = y_true[i]\n",
    "        pred_label = y_pred[i]\n",
    "\n",
    "        # Update confusion matrix counts based on true and predicted labels\n",
    "        if true_label == pred_label:\n",
    "            tp[true_label] += 1\n",
    "            for j in range(num_classes):\n",
    "                if j != true_label:\n",
    "                    tn[j] += 1\n",
    "        else:\n",
    "            fp[pred_label] += 1\n",
    "            fn[true_label] += 1\n",
    "            for j in range(num_classes):\n",
    "                if j != true_label and j != pred_label:\n",
    "                    tn[j] += 1\n",
    "\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27ac264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing values inside the tables to numbers which is assigned for each category. (Assigned values will be seen later)\n",
    "def convert_to_ids(table):\n",
    "    temp_table = np.empty_like(table)\n",
    "    for j in range(len(table)):\n",
    "        temp = table[j]\n",
    "        temp_table[j] = category_to_id.get(temp)\n",
    "    return temp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fd9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates and returns accuracy, precision and recall scores according to method to be used.\n",
    "# While calling this function we use parameters if it is weighted knn or not, if it is stop words deleted or not\n",
    "# and to decide which method will be used like bigram, unigram or tf-idf.\n",
    "# This function also takes the neighbour count parameter which will be 1 to 9 for this assignment.\n",
    "def calculate_scores(train, test, n, b_or_u, stop_removed, wtd):\n",
    "    X_train_1 = train.clean_text\n",
    "    y_train_1 = train.Category\n",
    "    X_test_1 = test.clean_text\n",
    "    y_test_1 = test.Category\n",
    "\n",
    "    vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "    if stop_removed:\n",
    "        if b_or_u == \"unigram\":\n",
    "            vec = CountVectorizer(ngram_range=(1, 1), stop_words=\"english\", max_features=100)\n",
    "        elif b_or_u == \"bigram\":\n",
    "            vec = CountVectorizer(ngram_range=(2, 2), stop_words=\"english\", max_features=100)\n",
    "        elif b_or_u == \"tf-idf\":\n",
    "            vec = TfidfVectorizer(ngram_range=(1, 2), max_features=1000, use_idf=True, stop_words=\"english\")\n",
    "        else:\n",
    "            print(\"There is an error in your code\")\n",
    "            sys.exit()\n",
    "    else:\n",
    "        if b_or_u == \"unigram\":\n",
    "            vec = CountVectorizer(ngram_range=(1, 1), max_features=100)\n",
    "        elif b_or_u == \"bigram\":\n",
    "            vec = CountVectorizer(ngram_range=(2, 2), max_features=100)\n",
    "        elif b_or_u == \"tf-idf\":\n",
    "            vec = TfidfVectorizer(ngram_range=(1, 2),max_features=1000, use_idf=True)\n",
    "        else:\n",
    "            print(\"There is an error in your code\")\n",
    "            sys.exit()\n",
    "\n",
    "    vec.fit(X_train_1)\n",
    "\n",
    "    X_transformed = vec.transform(X_train_1)\n",
    "    X_test_transformed = vec.transform(X_test_1)\n",
    "\n",
    "    X_transformed = X_transformed.toarray()\n",
    "    X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "    clf = KNN(k=n)\n",
    "    if wtd == \"yes\":  # If weighted knn will be used or not. If it will be used \"wtd\" will come as \"yes\" from parameter\n",
    "        clf = WeightedKNN(k=n)\n",
    "    clf.fit(X_transformed, y_train_1)\n",
    "    pred = clf.predict(X_test_transformed)\n",
    "\n",
    "    y_test_1 = y_test_1.to_numpy()\n",
    "\n",
    "    pred = convert_to_ids(pred)\n",
    "    pred = pred.astype(int)\n",
    "    y_test = convert_to_ids(y_test_1)\n",
    "\n",
    "    num_classes = 5\n",
    "    tp, tn, fp, fn = calculate_confusion_matrix(y_test, pred, num_classes)\n",
    "\n",
    "    # totals\n",
    "    tp_total = 0\n",
    "    tn_total = 0\n",
    "    fp_total = 0\n",
    "    fn_total = 0\n",
    "\n",
    "    # Calculate values for each category\n",
    "    for i in range(num_classes):\n",
    "        tp_total += tp[i]\n",
    "        tn_total += tn[i]\n",
    "        fp_total += fp[i]\n",
    "        fn_total += fn[i]\n",
    "\n",
    "    # averages\n",
    "    tp_avg = tp_total / 5\n",
    "    tn_avg = tn_total / 5\n",
    "    fp_avg = fp_total / 5\n",
    "    fn_avg = fn_total / 5\n",
    "\n",
    "    # Calculate accuracy, precision, recall scores\n",
    "    accuracy_total = (tp_avg + tn_avg) / (tp_avg + tn_avg + fn_avg + fp_avg)\n",
    "    precision = tp_avg / (tp_avg + fp_avg)\n",
    "    recall = tp_avg / (tp_avg + fn_avg)\n",
    "\n",
    "    return accuracy_total, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357cd1a",
   "metadata": {},
   "source": [
    "### Read, Visualize, Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f997aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset\n",
    "news_text = pd.read_csv('English Dataset.csv')\n",
    "np.seterr(divide='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5227b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business': 0, 'tech': 1, 'politics': 2, 'sport': 3, 'entertainment': 4}\n",
      "AxesSubplot(0.125,0.11;0.775x0.77)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize on data and preprocessing\n",
    "news_text['category_id'] = news_text['Category'].factorize()[0]\n",
    "category_id_df = news_text[['Category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Category']].values)\n",
    "print(category_to_id)\n",
    "print(news_text.groupby('Category').category_id.count().plot.bar(ylim=0))\n",
    "news_text.drop_duplicates(subset=['Category', 'Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04495ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text from whitespaces etc.\n",
    "def clean_text(text):\n",
    "    # remove everything except alphabets\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # remove whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "news_text['clean_text'] = news_text['Text'].apply(clean_text).str.replace('bn bn ', '')\n",
    "news_text['clean_text'] = news_text['Text'].apply(clean_text).str.replace(' bn ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18289e34",
   "metadata": {},
   "source": [
    "###  Analyse the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910ca9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Most 3 correlated words in business category:\n",
      "       . its\n",
      "       . bank\n",
      "       . growth\n",
      "# 'entertainment':\n",
      "  . Most 3 correlated words in entertainment category:\n",
      "       . actor\n",
      "       . best\n",
      "       . film\n",
      "# 'politics':\n",
      "  . Most 3 correlated words in politics category:\n",
      "       . election\n",
      "       . mr\n",
      "       . labour\n",
      "# 'sport':\n",
      "  . Most 3 correlated words in sport category:\n",
      "       . of\n",
      "       . cup\n",
      "       . england\n",
      "# 'tech':\n",
      "  . Most 3 correlated words in tech category:\n",
      "       . technology\n",
      "       . users\n",
      "       . mobile\n"
     ]
    }
   ],
   "source": [
    "# Below code section is for the see the most 3 correlated words for each category\n",
    "count_vec = CountVectorizer()\n",
    "features = count_vec.fit_transform(news_text.clean_text).toarray()\n",
    "labels = news_text.category_id\n",
    "\n",
    "N = 3\n",
    "\n",
    "for category, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)  # Do chi2 analyses of all items in this category\n",
    "    indices = np.argsort(\n",
    "        features_chi2[0])  # Sorts the indices of features_chi2[0] - the chi-squared stats of each feature\n",
    "    feature_names = np.array(count_vec.get_feature_names_out())[\n",
    "        indices]  # Converts indices to feature names ( in increasing order of chi-squared stat values)\n",
    "    unigrams = [v for v in feature_names if len(v.split(\n",
    "        ' ')) == 1]  # List of single word features ( in increasing order of chi-squared stat values)\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most 3 correlated words in\", category, \"category:\\n       . {}\".format(\n",
    "        '\\n       . '.join(unigrams[-N:])))  # Print the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4daf8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Most 10 correlated words for business category:\n",
      "       . firm\n",
      "       . prices\n",
      "       . profits\n",
      "       . economic\n",
      "       . yukos\n",
      "       . economy\n",
      "       . shares\n",
      "       . growth\n",
      "       . bank\n",
      "       . oil\n",
      "# 'entertainment':\n",
      "  . Most 10 correlated words for entertainment category:\n",
      "       . oscar\n",
      "       . singer\n",
      "       . award\n",
      "       . festival\n",
      "       . awards\n",
      "       . album\n",
      "       . best\n",
      "       . band\n",
      "       . actor\n",
      "       . film\n",
      "# 'politics':\n",
      "  . Most 10 correlated words for politics category:\n",
      "       . howard\n",
      "       . lib\n",
      "       . brown\n",
      "       . tories\n",
      "       . tory\n",
      "       . mr\n",
      "       . party\n",
      "       . election\n",
      "       . blair\n",
      "       . labour\n",
      "# 'sport':\n",
      "  . Most 10 correlated words for sport category:\n",
      "       . champion\n",
      "       . arsenal\n",
      "       . season\n",
      "       . win\n",
      "       . injury\n",
      "       . coach\n",
      "       . match\n",
      "       . chelsea\n",
      "       . england\n",
      "       . cup\n",
      "# 'tech':\n",
      "  . Most 10 correlated words for tech category:\n",
      "       . digital\n",
      "       . phones\n",
      "       . online\n",
      "       . computer\n",
      "       . technology\n",
      "       . broadband\n",
      "       . microsoft\n",
      "       . mobile\n",
      "       . software\n",
      "       . users\n"
     ]
    }
   ],
   "source": [
    "# Below code section is for the see the most 10 correlated words for each category\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 2),max_features=10000, use_idf=True)\n",
    "features2 = tfidf_vec.fit_transform(news_text.clean_text).toarray()\n",
    "\n",
    "N = 10\n",
    "\n",
    "for category, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2_2 = chi2(features2, labels == category_id)  # Do chi2 analyses of all items in this category\n",
    "    indices2 = np.argsort(\n",
    "        features_chi2_2[0])  # Sorts the indices of features_chi2[0] - the chi-squared stats of each feature\n",
    "    feature_names2 = np.array(tfidf_vec.get_feature_names_out())[\n",
    "        indices2]  # Converts indices to feature names ( in increasing order of chi-squared stat values)\n",
    "    unigrams2 = [v for v in feature_names2 if len(v.split(\n",
    "        ' ')) == 1]  # List of single word features ( in increasing order of chi-squared stat values)\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most 10 correlated words for\", category, \"category:\\n       . {}\".format(\n",
    "        '\\n       . '.join(unigrams2[-N:])))  # Print the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c8e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Most 10 correlated words (whose absence) for business category:\n",
      "       . headline\n",
      "       . priority\n",
      "       . lose\n",
      "       . reacted\n",
      "       . massive\n",
      "       . doubts\n",
      "       . doors\n",
      "       . enjoy\n",
      "       . ends\n",
      "       . courts\n",
      "# 'entertainment':\n",
      "  . Most 10 correlated words (whose absence) for entertainment category:\n",
      "       . ranking\n",
      "       . priced\n",
      "       . pm\n",
      "       . memories\n",
      "       . stood\n",
      "       . vision\n",
      "       . straight\n",
      "       . row\n",
      "       . impression\n",
      "       . millions\n",
      "# 'politics':\n",
      "  . Most 10 correlated words (whose absence) for politics category:\n",
      "       . keep\n",
      "       . sit\n",
      "       . satisfied\n",
      "       . walked\n",
      "       . row\n",
      "       . eastern\n",
      "       . patrick\n",
      "       . offensive\n",
      "       . region\n",
      "       . shop\n",
      "# 'sport':\n",
      "  . Most 10 correlated words (whose absence) for sport category:\n",
      "       . slump\n",
      "       . trick\n",
      "       . self\n",
      "       . kong\n",
      "       . classic\n",
      "       . disc\n",
      "       . initial\n",
      "       . poor\n",
      "       . permission\n",
      "       . robbie\n",
      "# 'tech':\n",
      "  . Most 10 correlated words (whose absence) for tech category:\n",
      "       . field\n",
      "       . sell\n",
      "       . ends\n",
      "       . unhappy\n",
      "       . worries\n",
      "       . substantial\n",
      "       . ground\n",
      "       . normal\n",
      "       . classic\n",
      "       . down\n"
     ]
    }
   ],
   "source": [
    "# Below code section is for the see the most 10 correlated words (whose absence) for each category\n",
    "for category, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2_2 = chi2(features2, labels == category_id)  # Do chi2 analyses of all items in this category\n",
    "    indices2 = np.argsort(\n",
    "        features_chi2_2[0])  # Sorts the indices of features_chi2[0] - the chi-squared stats of each feature\n",
    "    feature_names2 = np.array(tfidf_vec.get_feature_names_out())[\n",
    "        indices2]  # Converts indices to feature names ( in increasing order of chi-squared stat values)\n",
    "    unigrams2 = [v for v in feature_names2 if len(v.split(\n",
    "        ' ')) == 1]  # List of single word features ( in increasing order of chi-squared stat values)\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most 10 correlated words (whose absence) for\", category, \"category:\\n       . {}\".format(\n",
    "        '\\n       . '.join(unigrams2[:N])))  # Print the words whose absence most strongly predicts the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a067ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Most 10 correlated non-stopwords for business category:\n",
      "       . keen\n",
      "       . companies\n",
      "       . free\n",
      "       . terms\n",
      "       . graphics\n",
      "       . satisfied\n",
      "       . eminem\n",
      "       . expressed\n",
      "       . extraordinary\n",
      "       . ignore\n",
      "# 'entertainment':\n",
      "  . Most 10 correlated non-stopwords for entertainment category:\n",
      "       . person\n",
      "       . today\n",
      "       . otherwise\n",
      "       . believes\n",
      "       . theft\n",
      "       . catalogue\n",
      "       . adding\n",
      "       . presley\n",
      "       . argument\n",
      "       . arnold\n",
      "# 'politics':\n",
      "  . Most 10 correlated non-stopwords for politics category:\n",
      "       . ryan\n",
      "       . care\n",
      "       . ryanair\n",
      "       . investor\n",
      "       . meet\n",
      "       . blow\n",
      "       . ons\n",
      "       . public\n",
      "       . family\n",
      "       . lucrative\n",
      "# 'sport':\n",
      "  . Most 10 correlated non-stopwords for sport category:\n",
      "       . struck\n",
      "       . repeated\n",
      "       . keys\n",
      "       . car\n",
      "       . suit\n",
      "       . clint\n",
      "       . noon\n",
      "       . cement\n",
      "       . finally\n",
      "       . deaf\n",
      "# 'tech':\n",
      "  . Most 10 correlated non-stopwords for tech category:\n",
      "       . hoping\n",
      "       . contributions\n",
      "       . quoted\n",
      "       . bollywood\n",
      "       . wide\n",
      "       . parts\n",
      "       . reds\n",
      "       . reduction\n",
      "       . positions\n",
      "       . composer\n"
     ]
    }
   ],
   "source": [
    "# Below code section is for the see the most 10 correlated words after stopwords are removed for each category\n",
    "tfidf_vec2 = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, use_idf=True, stop_words=\"english\")\n",
    "features3 = tfidf_vec2.fit_transform(news_text.clean_text).toarray()\n",
    "for category, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2_3 = chi2(features3, labels == category_id)  # Do chi2 analyses of all items in this category\n",
    "    indices3 = np.argsort(\n",
    "        features_chi2_3[0])  # Sorts the indices of features_chi2[0] - the chi-squared stats of each feature\n",
    "    feature_names3 = np.array(tfidf_vec.get_feature_names_out())[\n",
    "        indices3]  # Converts indices to feature names ( in increasing order of chi-squared stat values)\n",
    "    unigrams3 = [v for v in feature_names3 if len(v.split(\n",
    "        ' ')) == 1]  # List of single word features ( in increasing order of chi-squared stat values)\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most 10 correlated non-stopwords for\", category, \"category:\\n       . {}\".format(\n",
    "        '\\n       . '.join(unigrams3[-N:])))  # Print the words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8f18e",
   "metadata": {},
   "source": [
    "### K-fold cross-validation/Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3006b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kFold starts here\n",
    "news_text = news_text.reindex(np.random.permutation(news_text.index))\n",
    "news_text = news_text.reset_index(drop=True)\n",
    "\n",
    "# Our data has length of 1440 which means each fold will be 288 long\n",
    "fold1 = news_text.loc[0:287]\n",
    "fold2 = news_text.loc[288:575]\n",
    "fold3 = news_text.loc[576:863]\n",
    "fold4 = news_text.loc[864:1151]\n",
    "fold5 = news_text.loc[1152:1439]\n",
    "\n",
    "\n",
    "# 5 different train and test values\n",
    "train_val1 = pd.concat([fold1, fold2, fold3, fold4])\n",
    "test_val1 = fold5\n",
    "\n",
    "train_val2 = pd.concat([fold1, fold2, fold3, fold5])\n",
    "test_val2 = fold4\n",
    "\n",
    "train_val3 = pd.concat([fold1, fold2, fold4, fold5])\n",
    "test_val3 = fold3\n",
    "\n",
    "train_val4 = pd.concat([fold1, fold3, fold4, fold5])\n",
    "test_val4 = fold2\n",
    "\n",
    "train_val5 = pd.concat([fold2, fold3, fold4, fold5])\n",
    "test_val5 = fold1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79180054",
   "metadata": {},
   "source": [
    "### More Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b26d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the accuracy, precision and recall scores for each method. It will be used in the next function.\n",
    "def print_scores(a1, a2, a3, a4, a5,\n",
    "                 p1, p2, p3, p4, p5,\n",
    "                 r1, r2, r3, r4, r5):\n",
    "    acc_avg = (a1 + a2 + a3 + a4 + a5) / 5\n",
    "    pre_avg = (p1 + p2 + p3 + p4 + p5) / 5\n",
    "    rec_avg = (r1 + r2 + r3 + r4 + r5) / 5\n",
    "\n",
    "    print(\"Accuracy = %.3f\" % acc_avg + \"   Precision = %.2f\" % pre_avg + \"   Recall = %.2f\" % rec_avg)\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e469845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run above functions (calculating scores, printing scores)\n",
    "# Also this function decides which k numbers (1 to 9) will be used according to parameters it will get.\n",
    "def run_and_print(uni_or_big_or_tf, removed, wtd, scnd):\n",
    "    if scnd == \"no\":\n",
    "        for x in range(1, 4, 2):\n",
    "            print(\"Testing for \", uni_or_big_or_tf + \" ||| k value for knn is : \", x)\n",
    "            if removed:\n",
    "                print(\"Stopwords are removed\")\n",
    "            else:\n",
    "                print(\"Stopwords are not removed\")\n",
    "            # print(\"k value for knn is : \", x)\n",
    "            acc1, pre1, rec1 = calculate_scores(train_val1, test_val1, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc2, pre2, rec2 = calculate_scores(train_val2, test_val2, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc3, pre3, rec3 = calculate_scores(train_val3, test_val3, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc4, pre4, rec4 = calculate_scores(train_val4, test_val4, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc5, pre5, rec5 = calculate_scores(train_val5, test_val5, x, uni_or_big_or_tf, removed, wtd)\n",
    "\n",
    "            print_scores(acc1, acc2, acc3, acc4, acc5,\n",
    "                         pre1, pre2, pre3, pre4, pre5,\n",
    "                         rec1, rec2, rec3, rec4, rec5)\n",
    "    elif scnd == \"yes\":\n",
    "        for x in range(5, 10, 2):\n",
    "            print(\"Testing for \", uni_or_big_or_tf + \" ||| k value for knn is : \", x)\n",
    "            if removed:\n",
    "                print(\"Stopwords are removed\")\n",
    "            else:\n",
    "                print(\"Stopwords are not removed\")\n",
    "            acc1, pre1, rec1 = calculate_scores(train_val1, test_val1, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc2, pre2, rec2 = calculate_scores(train_val2, test_val2, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc3, pre3, rec3 = calculate_scores(train_val3, test_val3, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc4, pre4, rec4 = calculate_scores(train_val4, test_val4, x, uni_or_big_or_tf, removed, wtd)\n",
    "            acc5, pre5, rec5 = calculate_scores(train_val5, test_val5, x, uni_or_big_or_tf, removed, wtd)\n",
    "\n",
    "            print_scores(acc1, acc2, acc3, acc4, acc5,\n",
    "                         pre1, pre2, pre3, pre4, pre5,\n",
    "                         rec1, rec2, rec3, rec4, rec5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11955c04",
   "metadata": {},
   "source": [
    "### Error Analysis for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49ea64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For commenting few misclassified examples\n",
    "train_val_for = pd.concat([fold1, fold2, fold3, fold4])\n",
    "test_val_for = fold5\n",
    "\n",
    "x_tr = train_val_for.clean_text\n",
    "y_tr = train_val_for.Category\n",
    "x_st = test_val_for.clean_text\n",
    "y_st = test_val_for.Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7844be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using unigram to see misclassifed examples\n",
    "vec = CountVectorizer(ngram_range=(1, 1), max_features=100)\n",
    "vec.fit(x_tr)\n",
    "\n",
    "X_transformed = vec.transform(x_tr)\n",
    "X_test_transformed = vec.transform(x_st)\n",
    "\n",
    "X_transformed = X_transformed.toarray()\n",
    "X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "clf_for = KNN(k=3)\n",
    "clf_for.fit(X_transformed, y_tr)\n",
    "\n",
    "y_pred_class = clf_for.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254cc736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. news that misclassified : \n",
      "microsoft gets the blogging bug software giant microsoft is taking the plunge into the world of blogging it is launching a test service to allow people to publish blogs or online journals called msn spaces microsoft is trailing behind competitors like google and aol which already offer services which make it easy for people to set up web journals blogs short for web logs have become a popular way for people to talk about their lives and express opinions online msn spaces is free to anyone with a hotmail or msn messenger account people will be able to choose a layout for the page upload images and share photo albums and music playlists the service will be supported by banner ads this is a simple tool for people to express themselves said msn s blake irving this is microsoft s first foray into blogging which has taken off as a web phenomenon in the past year competitors like google already offer free services through its blogger site while aol provides its members with journals accurate figures for the number of blogs in existence are hard to come by according to blog analysis firm technorati the so called blogosphere has doubled every five and a half months for the last months it now estimates that the number of blogs in existence has exceeded million although some speculate that less than a quarter are regularly maintained\n",
      "True Value is : tech ||| Prediction was : entertainment\n",
      "\n",
      "2. news that misclassified : \n",
      "argonaut founder rebuilds empire jez san the man behind the argonaut games group which went into administration a week ago has bought back most of the company the veteran games developer has taken over the cambridge based just add monsters studios and the london subsidiary morpheme the argonaut group went into administration due to a severe cash crisis firing about half of its staff in august it had warned of annual losses of m for the year to july jez san is one of the key figures in the uk s games industry the developer who received an obe in was estimated to have been worth more than m at the peak of the dotcom boom he founded argonaut in and has been behind titles such as starfox game more recently it was behind the harry potter games for the playstation but like all software developers argonaut needed a constant flow of deals with publishers in august it warned of annual losses of m blaming delays in signing new contracts and tough conditions in the software industry the group s three subsidiaries were placed in administration a week ago with mr sans resigning as the company s ceo and some staff being fired after the latest round of cuts there were workers at argonaut headquarters in edgware in north london with at its morpheme offices in kentish town london and at the just add monsters base in cambridge mr san has re emerged buying back morpheme and just add monsters we are pleased to announce the sale of these two businesses as going concerns said david rubin of administrators david rubin partners this has saved over jobs as well as the substantial employment claims that would have arisen had the sales not been achieved mr rubin said the administrators were in talks over the sale of the argonaut software division in edgware and were hopeful of finding a buyer this is a very difficult time for all the employees there but i salute their commitment to the business while we work towards a solution he said some former employees are angry at the way cash crisis was handled one told bbc news online that the staff who had been fired had been financially ruined in the space of a day\n",
      "True Value is : tech ||| Prediction was : business\n",
      "\n",
      "3. news that misclassified : \n",
      "no uk apology for colonial past the days of britain having to apologise for its colonial past are over gordon brown has said the chancellor speaking during a week long tour of africa said it was time to talk about enduring british values of liberty and tolerance mr brown has signed a debt relief deal with tanzania which could cost the uk billion south african president thabo mbeki has attacked british imperialists saying they treated africans like savages mr brown said that missionairies had come to africa because of their sense of duty he added that the history of internationalism and enterprise had given britain a greater global reach than any other country bbc political correspondent mark mardell said britishness had long been a theme of the chancellor s but never before has he been so outspoken in defending britain s past history the uk has pledged to pay of the developing world s foreign debt bill in an attempt to fight poverty on top of the relief deal with tanzania mr brown said the uk would make similar offers to poorer nations around the world under the plan which could cost the ukcountries must spend the cash saved on health education and welfare we make this offer unilaterally but we are now asking other countries to join us the chancellor said mr brown on a week long tour of africa spent two days in tanzania before heading on friday evening to mozambique a country where more than half of the million population lives below the poverty line there he is expected to strike a similar debt relief pact the chancellor said he hoped other g and european countries would follow suit the uk has already cancelled its bilateral debts money the uk alone is owed with the world s poorest nations including tanzania former international development secretary clare short questioned the effectiveness of debt relief as a means of tackling poverty\n",
      "True Value is : politics ||| Prediction was : business\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "for i in range(len(y_pred_class)):\n",
    "    if not np.equal(y_pred_class[i], y_st.iloc[i]):\n",
    "        found += 1\n",
    "        print(str(found) + \". news that misclassified : \")\n",
    "        print(x_st.iloc[i])\n",
    "        print(\"True Value is : \" + str(y_st.iloc[i]) + \" ||| Prediction was : \" + str(y_pred_class[i]))\n",
    "        print(\"\")\n",
    "        if found == 3:\n",
    "            break\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daa818e",
   "metadata": {},
   "source": [
    "#### Comments about misclassified samples  \n",
    "\n",
    "1 - In the first news there are words like blogs, journals maybe because of that algorithm classified it as entertainment instead of tech.  \n",
    "2 - Even though second news was about tech, algorithm classified it as business. I think the news is between business and tech\n",
    "There are lots of words which could be in business category thats why algorithm classified it wrong.  \n",
    "3 - In the last news i saw words like debt, bill, money. These words helped the algorithm to choose business and i saw lots of words could be related to politics category but all of them could be in different categories, i think that was the reasons that our algorithm misclassified this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2373616",
   "metadata": {},
   "source": [
    "#### Running all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f90d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to more organized and run the methods\n",
    "def run_final(weight, sec):\n",
    "    run_and_print(\"unigram\", False, weight, sec)\n",
    "    run_and_print(\"bigram\", False, weight, sec)\n",
    "    run_and_print(\"tf-idf\", False, weight, sec)\n",
    "    run_and_print(\"unigram\", True, weight, sec)\n",
    "    run_and_print(\"bigram\", True, weight, sec)\n",
    "    run_and_print(\"tf-idf\", True, weight, sec)\n",
    "\n",
    "\n",
    "# Function to be more organized and run the best 2 methods\n",
    "def run_best2(weight, sec):\n",
    "    run_and_print(\"tf-idf\", False, weight, sec)\n",
    "    run_and_print(\"tf-idf\", True, weight, sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a10ceb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for  unigram ||| k value for knn is :  1\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.838   Precision = 0.60   Recall = 0.60\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  3\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.850   Precision = 0.63   Recall = 0.63\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  1\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.785   Precision = 0.46   Recall = 0.46\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  3\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.788   Precision = 0.47   Recall = 0.47\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  1\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.956   Precision = 0.89   Recall = 0.89\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  3\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.960   Precision = 0.90   Recall = 0.90\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  1\n",
      "Stopwords are removed\n",
      "Accuracy = 0.892   Precision = 0.73   Recall = 0.73\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  3\n",
      "Stopwords are removed\n",
      "Accuracy = 0.896   Precision = 0.74   Recall = 0.74\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  1\n",
      "Stopwords are removed\n",
      "Accuracy = 0.841   Precision = 0.60   Recall = 0.60\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  3\n",
      "Stopwords are removed\n",
      "Accuracy = 0.845   Precision = 0.61   Recall = 0.61\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  1\n",
      "Stopwords are removed\n",
      "Accuracy = 0.962   Precision = 0.90   Recall = 0.90\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  3\n",
      "Stopwords are removed\n",
      "Accuracy = 0.966   Precision = 0.92   Recall = 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weighted = \"no\"  # To use KNN algorithm\n",
    "secondTime = \"no\"  # only for 1 to 3 k values\n",
    "run_final(weighted, secondTime)  # run all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be55c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Now for weighted knn algorithm ---\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  1\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.838   Precision = 0.60   Recall = 0.60\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  3\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.855   Precision = 0.64   Recall = 0.64\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  1\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.785   Precision = 0.46   Recall = 0.46\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  3\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.790   Precision = 0.48   Recall = 0.48\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  1\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.956   Precision = 0.89   Recall = 0.89\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  3\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.960   Precision = 0.90   Recall = 0.90\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  1\n",
      "Stopwords are removed\n",
      "Accuracy = 0.892   Precision = 0.73   Recall = 0.73\n",
      "\n",
      "Testing for  unigram ||| k value for knn is :  3\n",
      "Stopwords are removed\n",
      "Accuracy = 0.897   Precision = 0.74   Recall = 0.74\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  1\n",
      "Stopwords are removed\n",
      "Accuracy = 0.841   Precision = 0.60   Recall = 0.60\n",
      "\n",
      "Testing for  bigram ||| k value for knn is :  3\n",
      "Stopwords are removed\n",
      "Accuracy = 0.846   Precision = 0.62   Recall = 0.62\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  1\n",
      "Stopwords are removed\n",
      "Accuracy = 0.962   Precision = 0.90   Recall = 0.90\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  3\n",
      "Stopwords are removed\n",
      "Accuracy = 0.966   Precision = 0.92   Recall = 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Now for weighted knn algorithm ---\")\n",
    "print(\"\")\n",
    "weighted = \"yes\"  # To use weighted KNN algorithm\n",
    "run_final(weighted, secondTime)  # run all methods with weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0db0a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Now for best 2 methods ---\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  5\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.967   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  7\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.969   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  9\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.968   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  5\n",
      "Stopwords are removed\n",
      "Accuracy = 0.969   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  7\n",
      "Stopwords are removed\n",
      "Accuracy = 0.969   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  9\n",
      "Stopwords are removed\n",
      "Accuracy = 0.971   Precision = 0.93   Recall = 0.93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After the results we have seen that we got the best accuracies from tf-idf and tf-idf when stopwords are removed.\n",
    "print(\"--- Now for best 2 methods ---\")\n",
    "print(\"\")\n",
    "weighted = \"no\"  # To use KNN algorithm with best 2 method\n",
    "secondTime = \"yes\"  # only for 5 to 9 k values\n",
    "run_best2(weighted, secondTime)  # run best 2 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a58dee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Now for best 2 methods with weighted ---\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  5\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.967   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  7\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.968   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  9\n",
      "Stopwords are not removed\n",
      "Accuracy = 0.968   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  5\n",
      "Stopwords are removed\n",
      "Accuracy = 0.970   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  7\n",
      "Stopwords are removed\n",
      "Accuracy = 0.969   Precision = 0.92   Recall = 0.92\n",
      "\n",
      "Testing for  tf-idf ||| k value for knn is :  9\n",
      "Stopwords are removed\n",
      "Accuracy = 0.971   Precision = 0.93   Recall = 0.93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Now for best 2 methods with weighted ---\")\n",
    "print(\"\")\n",
    "weighted = \"yes\"  # To use weighted KNN algorithm with best 2 method\n",
    "run_best2(weighted, secondTime)  # run best 2 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d38484",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results_part1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15160\\1940163421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'results_part1.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 )\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results_part1.xlsx'"
     ]
    }
   ],
   "source": [
    "results = pd.read_excel('results_part1.xlsx')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16026cc6",
   "metadata": {},
   "source": [
    "We can see from the results:  \n",
    "\n",
    "We got the best accuracy with TF-IDF vectorizer when stopwords are removed and k was equal to 7.  \n",
    "In above scenario knn and weighted knn algorithm gave us similar accuracies.\n",
    "\n",
    "We got the worst accuracy with bigram when stopwords are not removed and k was equal to 1.  \n",
    "Again in above scenario both algorithms gave us similar accuracies.  \n",
    "\n",
    "From the results we saw that increasing k value doesn't have big impact on accuracies.  \n",
    "But removing stopwords slightly increases accuracy on all of methods.  \n",
    "\n",
    "In conclusion, we should use tf-idf vectorizer when working with this dataset for text classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2353121",
   "metadata": {},
   "source": [
    "# PART2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce492138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Imported these libraries to compare my results with ready methods\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870b85a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1b7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data\n",
    "data = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a634bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows/examples: 1338\n",
      "Number of columns/features: 7\n"
     ]
    }
   ],
   "source": [
    "#Checking data shape\n",
    "rows,columns = data.shape\n",
    "print(f\"Number of rows/examples: {rows}\")\n",
    "print(f\"Number of columns/features: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63765cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some examples from data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "098dbbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking null values and type of features\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4c306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "#changing type from object to int\n",
    "sex = le.fit_transform(data[\"sex\"])\n",
    "data[\"sex\"] = sex\n",
    "# Print the dtype for checking the transformation\n",
    "print(data[\"sex\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32d86f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "#changing type from object to int\n",
    "smoker = le.fit_transform(data[\"smoker\"])\n",
    "data[\"smoker\"] = smoker\n",
    "# Print the dtype for checking the transformation\n",
    "print(data[\"smoker\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e64ddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex     bmi  children  smoker      charges  region_northeast  \\\n",
      "0      19    0  27.900         0       1  16884.92400                 0   \n",
      "1      18    1  33.770         1       0   1725.55230                 0   \n",
      "2      28    1  33.000         3       0   4449.46200                 0   \n",
      "3      33    1  22.705         0       0  21984.47061                 0   \n",
      "4      32    1  28.880         0       0   3866.85520                 0   \n",
      "...   ...  ...     ...       ...     ...          ...               ...   \n",
      "1333   50    1  30.970         3       0  10600.54830                 0   \n",
      "1334   18    0  31.920         0       0   2205.98080                 1   \n",
      "1335   18    0  36.850         0       0   1629.83350                 0   \n",
      "1336   21    0  25.800         0       0   2007.94500                 0   \n",
      "1337   61    0  29.070         0       1  29141.36030                 0   \n",
      "\n",
      "      region_northwest  region_southeast  region_southwest  \n",
      "0                    0                 0                 1  \n",
      "1                    0                 1                 0  \n",
      "2                    0                 1                 0  \n",
      "3                    1                 0                 0  \n",
      "4                    1                 0                 0  \n",
      "...                ...               ...               ...  \n",
      "1333                 1                 0                 0  \n",
      "1334                 0                 0                 0  \n",
      "1335                 0                 1                 0  \n",
      "1336                 0                 0                 1  \n",
      "1337                 1                 0                 0  \n",
      "\n",
      "[1338 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#separating region to each reigon as a feature\n",
    "data = pd.get_dummies(data, columns = ['region']) \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e20c42",
   "metadata": {},
   "source": [
    "## MAE Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157dca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calculates the Mean Absolute Error\n",
    "#y_pred is predicted(inference) value, y is actual value\n",
    "def MAE(y_pred, y):\n",
    "    if len(y_pred.shape) > 1:\n",
    "        #squeeze deletes shape one shape dimension\n",
    "        y_pred = y_pred.squeeze()\n",
    "    mae = np.absolute(np.subtract(y_pred, y)).mean() \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8282558",
   "metadata": {},
   "source": [
    "# Ready Methods\n",
    "This part has codes for calculating MAE with ready methods.\n",
    "I use results of this part to compare the results of my methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e2c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the k values for KNN \n",
    "K = [1,3,5,7,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef22be0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def knn(data,weighted,normalize):\n",
    "    \n",
    "    #choose n_splits \n",
    "    kf = KFold(n_splits=5)\n",
    "    mae_val = [] #to store maealues for different k\n",
    "    \n",
    "    print(f\"model is weighted knn {weighted}\")  \n",
    "    print(f\"normalized is {normalize}\")\n",
    "    \n",
    "    for k in K:\n",
    "        #choose model\n",
    "        if(weighted):\n",
    "            model = neighbors.KNeighborsRegressor(n_neighbors = k,weights=\"distance\")\n",
    "        else:\n",
    "            model = neighbors.KNeighborsRegressor(n_neighbors = k)\n",
    "\n",
    "        #use that for normalization\n",
    "        if(normalize):\n",
    "            data = (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "        y = data[\"charges\"]\n",
    "        X = data.drop(\"charges\",axis=1)\n",
    "   \n",
    "        for train, test in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "            y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "            model.fit(X_train, y_train)  #fit the model\n",
    "            pred=model.predict(X_test) #make prediction on test set\n",
    "            error = MAE(y_test,pred) #calculate mae\n",
    "            mae_val.append(error) #store mae values\n",
    "        mae_mean = np.array(mae_val).mean()\n",
    "        print(f\"k is {k} , mean mae is {mae_mean}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3080418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is weighted knn False\n",
      "normalized is False\n",
      "k is 1 , mean mae is 7349.297019918624\n",
      "k is 3 , mean mae is 7346.283739437819\n",
      "k is 5 , mean mae is 7512.551345806799\n",
      "k is 7 , mean mae is 7642.497147353572\n",
      "k is 9 , mean mae is 7739.332423096279\n"
     ]
    }
   ],
   "source": [
    "#weighted, normalize\n",
    "knn(data,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87d060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is weighted knn False\n",
      "normalized is True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 1 , mean mae is 0.057173841875935286\n",
      "k is 3 , mean mae is 0.05687861258364607\n",
      "k is 5 , mean mae is 0.05724838376489897\n",
      "k is 7 , mean mae is 0.05773967115232039\n",
      "k is 9 , mean mae is 0.05817798063008617\n"
     ]
    }
   ],
   "source": [
    "knn(data,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baffb8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is weighted knn True\n",
      "normalized is False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 1 , mean mae is 7349.297019918624\n",
      "k is 3 , mean mae is 7291.247741557056\n",
      "k is 5 , mean mae is 7409.2820840541735\n",
      "k is 7 , mean mae is 7511.367198457624\n",
      "k is 9 , mean mae is 7594.47001813742\n"
     ]
    }
   ],
   "source": [
    "knn(data,True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ede665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is weighted knn True\n",
      "normalized is True\n",
      "k is 1 , mean mae is 0.057173841875935286\n",
      "k is 3 , mean mae is 0.05576452998078232\n",
      "k is 5 , mean mae is 0.05549190666126338\n",
      "k is 7 , mean mae is 0.0555658417422331\n",
      "k is 9 , mean mae is 0.05572449899584332\n"
     ]
    }
   ],
   "source": [
    "knn(data,True,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23f14e",
   "metadata": {},
   "source": [
    "## 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248d00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the fold of given index then returns train x, train y, test x, test y of that fold as a numpy array\n",
    "def create_splits(data, fold_index):\n",
    "    fold_size = len(data) // 5\n",
    "    start = fold_index * fold_size\n",
    "    end = start + fold_size\n",
    "\n",
    "    test_fold = data.loc[start:end]\n",
    "    train_folds = [data.loc[:start - 1], data.loc[end + 1:]]\n",
    "\n",
    "    train_set = pd.concat(train_folds)\n",
    "    test_set = test_fold\n",
    "\n",
    "    train_set_x = train_set.drop(\"charges\",axis=1)\n",
    "    train_set_y = train_set[\"charges\"]\n",
    "    test_set_x = test_set.drop(\"charges\",axis=1) \n",
    "    test_set_y = test_set[\"charges\"]\n",
    "\n",
    "    return train_set_x.to_numpy(), test_set_x.to_numpy(), train_set_y.to_numpy(), test_set_y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d298255",
   "metadata": {},
   "source": [
    "## KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00db42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates and returns the euclidean distance between to points\n",
    "def euclidean_distance(point1, point2):\n",
    "   \n",
    "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(point1, point2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd0c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN class for implementing both knn and weighted knn\n",
    "class KNN:\n",
    "    #Constructor takes k of knn and weighted for the knn as a parameter\n",
    "    def __init__(self, k=3, weighted=False):\n",
    "        self.k = k\n",
    "        self.weighted = weighted\n",
    "        \n",
    "    #fits the data\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    #predict target values of given X array\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([])\n",
    "        for x in X:\n",
    "            predictions = np.append(predictions, self._predict(x))\n",
    "        return predictions\n",
    "    \n",
    "    #predict the target value of given x\n",
    "    def _predict(self, x):\n",
    "        distances = np.array([])\n",
    "        #calculate the distances to other points in X\n",
    "        for x_train in self.X_train:\n",
    "            distance = euclidean_distance(x, x_train)\n",
    "            distances = np.append(distances, distance)\n",
    "\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        k_nearest_labels = np.array([])\n",
    "        #find the nearest k points\n",
    "        for i in k_indices:\n",
    "            k_nearest_labels = np.append(k_nearest_labels, self.y_train[i])\n",
    "        # if not weighted knn return the mean of the sum of k nearest point values \n",
    "        if not self.weighted:\n",
    "            return np.mean(k_nearest_labels)\n",
    "        # if weighted calculate weights using distances\n",
    "        else:\n",
    "            weights = 1 / (distances[k_indices] + 1e-6)  # Adding a small constant to avoid division by zero\n",
    "            weighted_values = k_nearest_labels * weights\n",
    "            return np.sum(weighted_values) / np.sum(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0024b1",
   "metadata": {},
   "source": [
    "## Running the KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd54bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes data, k of knn, weighted true or false, normalize true or false\n",
    "def knn(data,_k,_weighted,_normalize):\n",
    "    #create the model\n",
    "    model = KNN(k=_k, weighted=_weighted)\n",
    "    \n",
    "    print(f\"k is {_k}, weighted is {_weighted}, normalized is {_normalize}\")\n",
    "    #if normalize is true use min max normalization on data\n",
    "    if(_normalize):\n",
    "        data = (data-data.min())/(data.max()-data.min())\n",
    "    mae_val = [] #to store maealues for different k\n",
    "    \n",
    "    for i in range(5):\n",
    "        #for each fold\n",
    "        x_train, x_test, y_train, y_test = create_splits(data,i)\n",
    "\n",
    "        model.fit(x_train, y_train)  #fit the model\n",
    "        pred=model.predict(x_test) #make prediction on test set\n",
    "        error = MAE(y_test,pred) #calculate mae\n",
    "        mae_val.append(error) #store mae values\n",
    "        \n",
    "    #Calculating mean value of sum of each folds mae    \n",
    "    mae_mean = np.array(mae_val).mean()\n",
    "    print(f\"k is {model.k}, mean mae is {mae_mean}\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab8b6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 1, weighted is False, normalized is False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is 1, mean mae is 7416.003659417911\n",
      "k is 1, weighted is False, normalized is True\n",
      "k is 1, mean mae is 0.05675421611548097\n",
      "k is 1, weighted is True, normalized is False\n",
      "k is 1, mean mae is 7416.003659417911\n",
      "k is 1, weighted is True, normalized is True\n",
      "k is 1, mean mae is 0.05675421611548096\n",
      "\n",
      "k is 3, weighted is False, normalized is False\n",
      "k is 3, mean mae is 7375.982229020398\n",
      "k is 3, weighted is False, normalized is True\n",
      "k is 3, mean mae is 0.056393445061037516\n",
      "k is 3, weighted is True, normalized is False\n",
      "k is 3, mean mae is 7263.249088005623\n",
      "k is 3, weighted is True, normalized is True\n",
      "k is 3, mean mae is 0.054223095421717174\n",
      "\n",
      "k is 5, weighted is False, normalized is False\n",
      "k is 5, mean mae is 7853.88830949612\n",
      "k is 5, weighted is False, normalized is True\n",
      "k is 5, mean mae is 0.05768014183123209\n",
      "k is 5, weighted is True, normalized is False\n",
      "k is 5, mean mae is 7654.10003434004\n",
      "k is 5, weighted is True, normalized is True\n",
      "k is 5, mean mae is 0.0547163295637893\n",
      "\n",
      "k is 7, weighted is False, normalized is False\n",
      "k is 7, mean mae is 8040.862302602451\n",
      "k is 7, weighted is False, normalized is True\n",
      "k is 7, mean mae is 0.05905845947473337\n",
      "k is 7, weighted is True, normalized is False\n",
      "k is 7, mean mae is 7828.146017646664\n",
      "k is 7, weighted is True, normalized is True\n",
      "k is 7, mean mae is 0.05567050995344287\n",
      "\n",
      "k is 9, weighted is False, normalized is False\n",
      "k is 9, mean mae is 8140.105924290961\n",
      "k is 9, weighted is False, normalized is True\n",
      "k is 9, mean mae is 0.05982044937679911\n",
      "k is 9, weighted is True, normalized is False\n",
      "k is 9, mean mae is 7941.339464524384\n",
      "k is 9, weighted is True, normalized is True\n",
      "k is 9, mean mae is 0.05623662779165432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K = [1,3,5,7,9]\n",
    "for i in K:\n",
    "    knn(data,i,False,False)\n",
    "    knn(data,i,False,True)\n",
    "    knn(data,i,True,False)\n",
    "    knn(data,i,True,True)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67cdbe5",
   "metadata": {},
   "source": [
    "# Error Analysis for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82767f6",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae77e1",
   "metadata": {},
   "source": [
    "In this part of the assignment, the goal is to implement a nearest neighbor algorithm for estimating medical insurance costs. The dataset used for this task contains 1338 samples with continuous medical cost values. The features include age, sex, BMI, number of children, smoking status, and region. The implemented algorithm is extended to include a weighted k-NN approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831ac98",
   "metadata": {},
   "source": [
    "## Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c817e9",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09731276",
   "metadata": {},
   "source": [
    "The dataset was downloaded from the provided link and loaded into a Pandas DataFrame.  \n",
    "  \n",
    "The info() method was utilized to inspect null values and the types of features in the dataset.  \n",
    "  \n",
    "Object type features, such as 'sex' and 'smoker', were encoded using the LabelEncoder from scikit-learn to int.  \n",
    "  \n",
    "The 'region' feature was transformed using one-hot encoding, creating individual binary features for each region.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626e5f7",
   "metadata": {},
   "source": [
    "### 2. MAE Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b33456",
   "metadata": {},
   "source": [
    "The Mean Absolute Error (MAE) is a crucial metric for evaluating the performance of the regression model. It quantifies the average absolute difference between the predicted and actual values.  \n",
    "  \n",
    "This function takes the predicted values (y_pred) and the actual values (y) as inputs and computes the mean absolute difference between them. It is a reliable measure of how well the model is performing in estimating medical insurance costs.  \n",
    "  \n",
    "The MAE values will be utilized to assess and compare the performance of different k-NN and weighted k-NN models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9059c",
   "metadata": {},
   "source": [
    "### 3. 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e45c1",
   "metadata": {},
   "source": [
    "A 5-fold cross-validation method was applied to measure the performance of the model.  \n",
    "This method creates the fold of given index then returns train x, train y, test x, test y of that fold as a numpy array.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e811b51",
   "metadata": {},
   "source": [
    "### 4. KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6978d07",
   "metadata": {},
   "source": [
    "#### k-NN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded2eb6",
   "metadata": {},
   "source": [
    "The k-NN algorithm for regression was implemented using Euclidean distance as the distance metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8475715",
   "metadata": {},
   "source": [
    "#### Weighted k-NN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60210961",
   "metadata": {},
   "source": [
    "An extension of the k-NN algorithm, the weighted k-NN algorithm, was implemented. This approach assigns different weights to neighbors based on their distance, giving more influence to closer neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0695dd",
   "metadata": {},
   "source": [
    "### 5. K-NN Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f146a1",
   "metadata": {},
   "source": [
    "The knn function implements the k-NN algorithm for medical insurance cost estimation. It takes the dataset (data), the number of neighbors (_k), a boolean flag for weighted k-NN (_weighted), and a boolean flag for feature normalization (_normalize) as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a11e3b5",
   "metadata": {},
   "source": [
    "Steps:  \n",
    "1.Model Initialization:  \n",
    "A k-NN model is created using the provided parameters.  \n",
    "  \n",
    "2.Data Normalization:  \n",
    "If _normalize is set to True, min-max normalization is applied to the dataset.  \n",
    "  \n",
    "3.5-Fold Cross-Validation:  \n",
    "The model is trained and evaluated using 5-fold cross-validation.  \n",
    "Mean Absolute Error (MAE) values are calculated for each fold.  \n",
    "  \n",
    "4.Performance Analysis:  \n",
    "The mean MAE value across all folds is computed.  \n",
    "Results, including the values of k, whether the algorithm is weighted, and   whether normalization is applied, are printed for analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6f92f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9556854d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k values of knn</th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=3</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=7</th>\n",
       "      <th>k=9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn ready method</td>\n",
       "      <td>7349.297010</td>\n",
       "      <td>7346.28373</td>\n",
       "      <td>7512.55134</td>\n",
       "      <td>7642.49714</td>\n",
       "      <td>7739.332420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn my implementation</td>\n",
       "      <td>7416.003650</td>\n",
       "      <td>7375.98222</td>\n",
       "      <td>7853.88830</td>\n",
       "      <td>8040.86230</td>\n",
       "      <td>8140.105924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn ready method normalized</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.05687</td>\n",
       "      <td>0.05724</td>\n",
       "      <td>0.05773</td>\n",
       "      <td>0.058170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn my implementation normalized</td>\n",
       "      <td>0.056754</td>\n",
       "      <td>0.05639</td>\n",
       "      <td>0.05768</td>\n",
       "      <td>0.05905</td>\n",
       "      <td>0.059820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted knn ready method</td>\n",
       "      <td>7349.297010</td>\n",
       "      <td>7291.24774</td>\n",
       "      <td>7409.28200</td>\n",
       "      <td>7511.36719</td>\n",
       "      <td>7594.470010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted knn my implementation</td>\n",
       "      <td>7416.003650</td>\n",
       "      <td>7263.24908</td>\n",
       "      <td>7654.10003</td>\n",
       "      <td>7828.14601</td>\n",
       "      <td>7941.339460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted knn ready method normalized</td>\n",
       "      <td>0.057170</td>\n",
       "      <td>0.05576</td>\n",
       "      <td>0.05549</td>\n",
       "      <td>0.05556</td>\n",
       "      <td>0.055720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted knn my implementation normalized</td>\n",
       "      <td>0.056754</td>\n",
       "      <td>0.05422</td>\n",
       "      <td>0.05471</td>\n",
       "      <td>0.05567</td>\n",
       "      <td>0.056236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             k values of knn          k=1         k=3  \\\n",
       "0                           knn ready method  7349.297010  7346.28373   \n",
       "1                      knn my implementation  7416.003650  7375.98222   \n",
       "2                knn ready method normalized     0.057170     0.05687   \n",
       "3           knn my implementation normalized     0.056754     0.05639   \n",
       "4                  weighted knn ready method  7349.297010  7291.24774   \n",
       "5             weighted knn my implementation  7416.003650  7263.24908   \n",
       "6       weighted knn ready method normalized     0.057170     0.05576   \n",
       "7  weighted knn my implementation normalized     0.056754     0.05422   \n",
       "\n",
       "          k=5         k=7          k=9  \n",
       "0  7512.55134  7642.49714  7739.332420  \n",
       "1  7853.88830  8040.86230  8140.105924  \n",
       "2     0.05724     0.05773     0.058170  \n",
       "3     0.05768     0.05905     0.059820  \n",
       "4  7409.28200  7511.36719  7594.470010  \n",
       "5  7654.10003  7828.14601  7941.339460  \n",
       "6     0.05549     0.05556     0.055720  \n",
       "7     0.05471     0.05567     0.056236  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Some results that I have saved before\n",
    "results = pd.read_excel('results_part2.xlsx')\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35a22f",
   "metadata": {},
   "source": [
    "As seen in the results,  \n",
    "  \n",
    "In both unnormalized and normalized results, the ready method demonstrates slightly better performance.  \n",
    "Normalized results are significantly less than unnormalized data mae value. That suggests normalization of the data is a must for better results.  \n",
    "Lesser the mae means better the accuracy of the model.  \n",
    "  \n",
    "For knn ready method best k value is 3  \n",
    "For knn my implementation best k value is 3  \n",
    "For knn ready method normalized best k value is 3  \n",
    "For knn my implementation normalized best k value is 3  \n",
    "For weighted knn ready method best k value is 3  \n",
    "For weighted knn my implementation best k value is 3  \n",
    "For weighted knn ready method normalized best k value is 5  \n",
    "For weighted knn my implementation normalized best k value is 3  \n",
    "On average best k value for this data is 3  \n",
    "  \n",
    "Lowest error has observed for weighted knn in my implementation with normalized data for k=3 , with the mae error 0.05422.    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b95aaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
